{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsupervised multiclass classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWTYHkbzxbwA"
      },
      "outputs": [],
      "source": [
        "#import libaries\n",
        "import numpy as np\n",
        "from numpy import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Aux methods:\n",
        "def is_pos_def(x):\n",
        "    return np.all(np.linalg.eigvals(x) > 0)\n",
        "\n",
        "def check_all_matrices(x):\n",
        "  b = True\n",
        "  for m in x:\n",
        "    b = b and is_pos_def(m)\n",
        "    if not b: return False\n",
        "  return b"
      ],
      "metadata": {
        "id": "yBT8mKPe2Pgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate dataset\n",
        "n = 50000 #datapoints\n",
        "d = 3 #dimensions\n",
        "c = 3 #number of clusters\n",
        "\n",
        "def create_cov_matrices(cov_list):\n",
        "  for m in cov_list:\n",
        "    np.fill_diagonal(m, abs(random.normal(size=(d), scale=spread_of_cluster_centre)))\n",
        "\n",
        "def generate_dataset(mean_list, cov_list, n):\n",
        "  x_features = []\n",
        "  y_labels = random.choice(c, n)\n",
        "  for i in range(n):\n",
        "    rand_c = y_labels[i]\n",
        "    mean = mean_list[rand_c]\n",
        "    cov = cov_list[rand_c]\n",
        "    datapoint = np.random.multivariate_normal(mean,cov,(1))\n",
        "    [datapoint] = datapoint\n",
        "    x_features.append(datapoint)\n",
        "  x_features = np.array(x_features)\n",
        "  return (x_features, y_labels)\n",
        "\n",
        "spread_of_cluster_centre = math.pi * 3\n",
        "spread_around_clusters = math.pi * 3\n",
        "cluster_centres = random.normal(size=(c,d), scale=spread_of_cluster_centre, loc=random.normal(spread_around_clusters))\n",
        "# print(cluster_centres)\n",
        "\n",
        "temp = []\n",
        "for c_i in range(c):\n",
        "  temp.append(np.zeros((d,d), float))\n",
        "cov_matrices_list = np.array(temp)\n",
        "# z = np.zeros((d,d), float)\n",
        "# cov_matrices_list = np.repeat(z[:, :, np.newaxis], c, axis=2)\n",
        "# print(cov_matrices_list)\n",
        "create_cov_matrices(cov_matrices_list)\n",
        "\n",
        "# print(check_all_matrices(cov_matrices_list))\n",
        "x_features, y_labels = generate_dataset(cluster_centres, cov_matrices_list, n)\n",
        "\n",
        "# print(cluster_centres)\n",
        "# print()\n",
        "# print(cov_matrices_list)\n",
        "# print()\n",
        "# print(x_features)\n",
        "# print()\n",
        "# print(y_labels)\n",
        "\n",
        "#Data preprocessing\n",
        "x_training_data = x_features\n",
        "y_training_label = y_labels"
      ],
      "metadata": {
        "id": "XT4SlXqa291E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Data preprocessing\n",
        "x_training_data = x_features\n",
        "y_training_label = y_labels"
      ],
      "metadata": {
        "id": "fZgMHkdz6KPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_training_data, y_training_label, random_state=42, test_size=0.2)\n",
        "k_means = KMeans(n_clusters=c, random_state=42, max_iter=100000, tol=1e-6).fit(X_train)\n",
        "# print(k_means.score(X_test))\n",
        "\n",
        "print(\"Misclassification: \" + str( (k_means.predict(X_test)!=y_test).sum()) + \" out of \" + str (len(y_test)))\n",
        "\n",
        "print(np.sort(cluster_centres, axis=0))\n",
        "print(np.sort(k_means.cluster_centers_, axis=0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g_rON4o03BBk",
        "outputId": "587b8db2-c70a-49ec-a102-800012215fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misclassification: 270 out of 10000\n",
            "[[ 5.83832053  4.94949314 -7.50939998]\n",
            " [ 8.37182699  9.63217153  6.7041573 ]\n",
            " [17.6745843  14.61441055 11.97147719]]\n",
            "[[ 5.83408253  5.13411771 -7.50158203]\n",
            " [ 8.19232523  9.57573555  7.03995519]\n",
            " [17.68470834 15.2256476  11.99788309]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GMM\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_training_data, y_training_label, random_state=42, test_size=0.2)\n",
        "gm = GaussianMixture(n_components=c, covariance_type = \"full\", tol=1e-6, max_iter=10000, random_state=42, warm_start=True).fit(X_train)\n",
        "\n",
        "print(\"Misclassification: \" + str( (gm.predict(X_test)!=y_test).sum()) + \" out of \" + str (len(y_test)))\n",
        "print(\"Score: \" + str(gm.score(X_test)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjC6n5HW144a",
        "outputId": "69246abf-ca62-45ed-e572-a06a1c5fe989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misclassification: 9989 out of 10000\n",
            "Score: -7.9973906022864885\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_training_data, y_training_label, random_state=42, test_size=0.3)\n",
        "aff_prop_clustering = AgglomerativeClustering(n_clusters=c).fit(X_train)\n",
        "print(\"Misclassification: \" + str( (aff_prop_clustering.fit_predict(X_test)!=y_test).sum()) + \" out of \" + str (len(y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74Od7XAtunq0",
        "outputId": "75d8ac9e-8be0-41f1-979e-f4610591b2f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Misclassification: 14988 out of 15000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import MeanShift\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_training_data, y_training_label, random_state=42, test_size=0.3)\n",
        "mean_shift_cluster = MeanShift(bandwidth=2).fit(X_train)\n",
        "print(\"Misclassification: \" + str( (mean_shift_cluster.predict(X_test)!=y_test).sum()) + \" out of \" + str (len(y_test)))"
      ],
      "metadata": {
        "id": "a49PYGgNrWdf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import AffinityPropagation\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(x_training_data, y_training_label, random_state=42, test_size=0.3)\n",
        "aff_prop_clustering = AffinityPropagation(random_state=42, max_iter=20000).fit(X_train)\n",
        "print(\"Misclassification: \" + str( (aff_prop_clustering.predict(X_test)!=y_test).sum()) + \" out of \" + str (len(y_test)))"
      ],
      "metadata": {
        "id": "yLLyuZF9twM4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}